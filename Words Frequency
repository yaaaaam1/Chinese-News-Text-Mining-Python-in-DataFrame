# After preprocessing, we can count Chinese words frequency

import pandas as pd
import jieba
import re
from sklearn.feature_extraction.text import TfidfVectorizer

# Words Frequency 中文詞彙數
# using tfidf
tf_vectorizer = CountVectorizer(strip_accents = None, stop_words='english')

year = 13
for news in net:
    tf = tf_vectorizer.fit_transform(news.cutted)
    words = np.array(tf_vectorizer.get_feature_names())
    weight = tf.toarray().sum(axis = 0)
    wordfq = pd.DataFrame({'word':words,'freq':weight})
    wordfq.sort_values(by = 'freq',inplace = True, ascending = False)
    wordfq.to_csv('D:/python/Text Mining/1016wordsfq/int%s.csv'%year,encoding = 'cp950',index = False)
    year+=1
